{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a978b014",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "import re\n",
    "import string\n",
    "import zipfile\n",
    "\n",
    "import numpy as np\n",
    "import scipy.sparse as sparse   \n",
    "from scipy.sparse.linalg import svds\n",
    "from scipy.sparse import find\n",
    "from scipy.sparse import csr_matrix\n",
    "from pandas import read_csv\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dfc9a222",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StemmerWrapper:\n",
    "    \"\"\" Class wrapper to some language stemmer; Via wrapping, I think,\n",
    "        it is comfortable to operate with stemmer and functions,\n",
    "        that formats text for systems.\n",
    "    \"\"\"\n",
    "    def __init__(self, lang=\"russian\"):\n",
    "        \"\"\"\n",
    "        :param lang: Initializing stemmer with setting `lang` language\n",
    "        \"\"\"\n",
    "        self.stemmer = SnowballStemmer(lang)\n",
    "\n",
    "    def stem(self, *args, **kwargs):\n",
    "        \"\"\" just for beauty and comfortable call\"\"\"\n",
    "        return self.stemmer.stem(*args, **kwargs)\n",
    "\n",
    "    @staticmethod\n",
    "    def clean_string(sample_s: str) -> str:\n",
    "        \"\"\"\n",
    "        :param sample_s: string to be formatted\n",
    "        :return: formatted string\n",
    "        formats given string by removing unnecessary components for\n",
    "        building recommendation systems\n",
    "        \"\"\"\n",
    "        # string to lowercase\n",
    "        sample_s = sample_s.strip().lower()\n",
    "        # removing one-symbol words\n",
    "        sample_s = re.sub(r'\\b[ЁёА-я]{1}\\b', '', sample_s)\n",
    "        # removing punctuation\n",
    "        sample_s = re.sub(r'[%s]' % re.escape(string.punctuation), ' ',\n",
    "                          sample_s)\n",
    "        # removing one-digit numbers\n",
    "        sample_s = re.sub(r'\\b[0-9]{1}\\b', '', sample_s)\n",
    "        # replacing several-in-a-row space symbols with only one space\n",
    "        sample_s = re.sub(r'\\s+', ' ', sample_s)\n",
    "        return sample_s.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc2ad076",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loader:\n",
    "    \"\"\"\n",
    "    Class represents data-loader for systems. This is a base-class,\n",
    "    so some virtual function must be overwritten.\n",
    "    \"\"\"\n",
    "    def __init__(self, stemmer):\n",
    "        \"\"\"\n",
    "        :param stemmer: language stemmer to be used\n",
    "        \"\"\"\n",
    "        self.stemmer = stemmer\n",
    "\n",
    "    def merge_contents(self,\n",
    "                       table: str,\n",
    "                       main_id: str,\n",
    "                       content_cname: str,\n",
    "                       columns: list):\n",
    "        \"\"\"\n",
    "        merges content of selected `columns` from `table`;\n",
    "        check overwritten function for more info.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    @staticmethod\n",
    "    def split_series(series):\n",
    "        \"\"\"\n",
    "        :return: (pd.core.series.Series) updated `series`-copy\n",
    "        :param series: (pd.core.series.Series)\n",
    "        Splitting values in cell's of column `series` (in-place)\n",
    "        \"\"\"\n",
    "        # handling None values separately\n",
    "        return series.apply(lambda x: x.split() if type(x) == str else [])\n",
    "\n",
    "    def format_columns(self,\n",
    "                       dataframe,\n",
    "                       main_id_cname: str,\n",
    "                       content_cname: str,\n",
    "                       columns: list):\n",
    "        \"\"\"\n",
    "        :param dataframe: contains data to be formatted and used\n",
    "        :param main_id_cname: item-representing-column's name\n",
    "        :param content_cname: content-representing-column's name\n",
    "        :param columns: names of columns in dataframe\n",
    "        :return: 2-column dataframe, named as main_id_cname and\n",
    "            content_cname; second columns contains formatted\n",
    "            and merged `columns` content\n",
    "        \"\"\"\n",
    "        # initializing new column in dataframe with empty strings\n",
    "        dataframe[content_cname] = ''\n",
    "\n",
    "        # remember items-id-representing column\n",
    "        id_series = dataframe[main_id_cname]\n",
    "\n",
    "        # set dataframe to a `columns`-containing table,\n",
    "        # where all string infos was split into lists\n",
    "        dataframe = dataframe[[content_cname] + columns].apply(\n",
    "                self.split_series)\n",
    "\n",
    "        # formatting all rows\n",
    "        # firstly, we put add all lists to content containing column\n",
    "        dataframe[content_cname] = reduce(\n",
    "                lambda prev, el: prev + dataframe[el],\n",
    "                columns,\n",
    "                dataframe[content_cname]\n",
    "        ).apply(  # then we would stem all words in this column\n",
    "                lambda iterable: [self.stemmer.stem(w) for w in iterable]\n",
    "        ).apply(  # lastly, we join lists to string\n",
    "                lambda iterable: ' '.join(iterable)\n",
    "        ).apply(\n",
    "                StemmerWrapper.clean_string\n",
    "        )\n",
    "\n",
    "        # set item-representing-column's data\n",
    "        dataframe[main_id_cname] = id_series\n",
    "\n",
    "        # return table representing relationship item\n",
    "        return dataframe[[main_id_cname, content_cname]]\n",
    "\n",
    "    def parse(self, table: str, columns: list):\n",
    "        \"\"\"\n",
    "        parses selected `columns` from `table`;\n",
    "        check overwritten function for more info.\n",
    "        \"\"\"\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d113db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CsvLoader(Loader):\n",
    "    \"\"\"\n",
    "    Represents data-loader from csv-file\n",
    "    \"\"\"\n",
    "    def __init__(self, stemmer):\n",
    "        \"\"\"\n",
    "        :param stemmer: language stemmer to be used\n",
    "        \"\"\"\n",
    "        super().__init__(stemmer)\n",
    "\n",
    "    def merge_contents(self,\n",
    "                       path: str,\n",
    "                       main_id_cname: str,\n",
    "                       content_cname: str,\n",
    "                       columns: list):\n",
    "        \"\"\"\n",
    "        :param path: (str) path to table, where from data will be read\n",
    "        :param main_id_cname: (str) item-representing-column's name;\n",
    "            it is explicit for `path` to have such column\n",
    "        :param content_cname: (str) content-representing-column's name\n",
    "        :param columns: (list) columns containing main content,\n",
    "            that will be used to build a content-based model\n",
    "        :return: (pd.core.frame.DataFrame) 2-column dataframe\n",
    "            representing relationship of item and it's content\n",
    "            (one-to-one relationship)\n",
    "        \"\"\"\n",
    "        return self.format_columns(\n",
    "                self.parse(path, columns + [main_id_cname]),\n",
    "                main_id_cname,\n",
    "                content_cname,\n",
    "                columns\n",
    "        )\n",
    "\n",
    "    def parse(self, table: str, columns: list):\n",
    "        \"\"\"\n",
    "        :param table: database table name\n",
    "        :param columns: columns to be parsed\n",
    "        :return: dataframe with parsed columns\n",
    "        \"\"\"\n",
    "        return read_csv(\n",
    "                table,\n",
    "                skipinitialspace=True,\n",
    "                usecols=columns\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e363541",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecommendationSystem:\n",
    "    \"\"\"\n",
    "    Root-class representing recommendation system\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def load_and_build(self, *args):\n",
    "        pass\n",
    "\n",
    "    def load(self, *args):\n",
    "        pass\n",
    "\n",
    "    def build(self, *args):\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ad95761",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CollaborativeFiltering(RecommendationSystem):\n",
    "    \"\"\"\n",
    "    Represents recommendation system based on collaborative-filtering\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(CollaborativeFiltering, self).__init__()\n",
    "        # sparse matrix of implicit user-item interactions\n",
    "        self.sparse_matrix = None\n",
    "\n",
    "        # dataframes, so we could map indices used in class\n",
    "        # methods with indices used in database\n",
    "        self.user_indices_decode = None\n",
    "        self.item_indices_decode = None\n",
    "\n",
    "        # column names in database corresponding to user and item\n",
    "        self.user_cname = None\n",
    "        self.item_cname = None\n",
    "\n",
    "    def load(self,\n",
    "             table: str,\n",
    "             columns: list,\n",
    "             loader_type: str = \"csv\",\n",
    "             connection=None):\n",
    "        \"\"\"\n",
    "        :param table: table name where from data will be read (this\n",
    "            either table of database or path to csv file, depending\n",
    "            on loader_typ)\n",
    "        :param columns: 2 or 3 elements array - names of columns of\n",
    "            user, item and their relationship coefficients (if it's\n",
    "            provided)\n",
    "        :param loader_type: equals either to \"csv\" or \"db\", depending\n",
    "            on `table`\n",
    "        :param connection: if loader_type equals to db, it must be\n",
    "            connection to using database (otherwise - whatever)\n",
    "\n",
    "        Loads data necessary to build model\n",
    "        \"\"\"\n",
    "        # check for `columns` length\n",
    "        if len(columns) < 2 or len(columns) > 3:\n",
    "            raise RuntimeError(\"CollaborativeFiltering::load: columns \"\n",
    "                               \"argument invalid format\")\n",
    "\n",
    "        # initialize loader\n",
    "        if loader_type == \"csv\":\n",
    "            loader = CsvLoader(None)\n",
    "        elif loader_type == \"db\":\n",
    "            if connection is None:\n",
    "                raise RuntimeError(\"CollaborativeFiltering::load: received \"\n",
    "                                   \"connection equals to None with a \"\n",
    "                                   \"loader_type equals db\")\n",
    "            loader = DataBaseLoader(None, connection)\n",
    "        else:\n",
    "            raise RuntimeError(\"CollaborativeFiltering::load: no loader \"\n",
    "                               \"available for given loader_type\")\n",
    "\n",
    "        # load implicit data in 3-column dataframe\n",
    "        dataframe = loader.parse(table, columns)\n",
    "        dataframe.dropna(inplace=True)\n",
    "\n",
    "        relations_count = dataframe.shape[0]\n",
    "        # copying column names explicitly\n",
    "        self.user_cname, self.item_cname = columns[0] + \"\", columns[1] + \"\"\n",
    "        user_id_cname, item_id_cname = columns[0] + \"_id\", columns[1] + \"_id\"\n",
    "\n",
    "        # save user and item columns, so we will be able to return to\n",
    "        # caller recommendation as it is stored in database\n",
    "        dataframe[user_id_cname] = dataframe[columns[0]].astype(\n",
    "                \"category\").cat.codes\n",
    "        dataframe[item_id_cname] = dataframe[columns[1]].astype(\n",
    "                \"category\").cat.codes\n",
    "        self.user_indices_decode = dataframe[\n",
    "            [user_id_cname, columns[0]]].drop_duplicates()\n",
    "        self.item_indices_decode = dataframe[\n",
    "            [item_id_cname, columns[1]]].drop_duplicates()\n",
    "        dataframe.drop(columns[:2], axis=1, inplace=True)\n",
    "\n",
    "        # initializing sparse matrix\n",
    "        users = dataframe[user_id_cname].astype(int)\n",
    "        items = dataframe[item_id_cname].astype(int)\n",
    "        users_count = len(dataframe[user_id_cname].unique())\n",
    "        items_count = len(dataframe[item_id_cname].unique())\n",
    "        if len(columns) == 3:\n",
    "            self.sparse_matrix = sparse.csr_matrix(\n",
    "                    (dataframe[columns[2]], (users, items)),\n",
    "                    shape=(users_count, items_count)\n",
    "            )\n",
    "        elif len(columns) == 2:\n",
    "            self.sparse_matrix = sparse.csr_matrix(\n",
    "                    ([1 for _ in range(relations_count)], (users, items)),\n",
    "                    shape=(users_count, items_count)\n",
    "            )\n",
    "\n",
    "    def _item2index(self,\n",
    "                    item):\n",
    "        \"\"\"\n",
    "        :param item: item as it is stored in database\n",
    "        :return: index used in this object for `item`\n",
    "        \"\"\"\n",
    "        return self.item_indices_decode[\n",
    "            self.item_cname + \"_id\"\n",
    "            ].loc[self.item_indices_decode[self.item_cname] == item].iloc[0]\n",
    "\n",
    "    def _user2index(self,\n",
    "                    user):\n",
    "        \"\"\"\n",
    "        :param user: user as it is stored in database\n",
    "        :return: index used in this object for `user`\n",
    "        \"\"\"\n",
    "        return self.user_indices_decode[\n",
    "            self.user_cname + \"_id\"\n",
    "            ].loc[self.user_indices_decode[self.user_cname] == user].iloc[0]\n",
    "\n",
    "    def _index2item(self,\n",
    "                    items_ids: list):\n",
    "        \"\"\"\n",
    "        :param items_ids: list of indices as they are stored in this\n",
    "            object\n",
    "        :return: corresponding to `indices` values of items\n",
    "        \"\"\"\n",
    "        result = list()\n",
    "        for item_id in items_ids:\n",
    "            result.append(\n",
    "                    self.item_indices_decode[\n",
    "                        self.item_cname\n",
    "                    ].loc[\n",
    "                        self.item_indices_decode[\n",
    "                            self.item_cname + \"_id\"] == item_id\n",
    "                        ].iloc[0]\n",
    "            )\n",
    "        return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f2d0c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ComplementItemRS(CollaborativeFiltering):\n",
    "    \"\"\"\n",
    "    Class represents recommendation system, that recommends items,\n",
    "    which are most suitable to some user based on experience of\n",
    "    what other users like he liked/used.\n",
    "    Actually, it can be used as complement items recommendation system,\n",
    "    if user would be set to some `order`-type (so we will see what\n",
    "    to recommend into user's shopping cart).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(ComplementItemRS, self).__init__()\n",
    "        # items similarities matrix (items x items)\n",
    "        self.similarities = None\n",
    "        # items similarities matrix QR-decomposition matrices\n",
    "        self.sim_q, self.sim_r = None, None\n",
    "        # fast-recommendations matrix\n",
    "        self.recommendations = None\n",
    "        # use to save memory resources from lots of data possibly\n",
    "        # never been recommended\n",
    "        self.fast_reqs_limit = -1\n",
    "\n",
    "    def set_limit(self, value: int = 100):\n",
    "        \"\"\"\n",
    "        :param value: new value to be set\n",
    "        \"\"\"\n",
    "        self.fast_reqs_limit = value\n",
    "\n",
    "    def build(self,\n",
    "              via_normalize: bool = False,\n",
    "              big_data: bool = False):\n",
    "        \"\"\"\n",
    "        :param via_normalize: set true if want to normalize items'\n",
    "            vectors. They can be normalized for the situations, where\n",
    "            opinion of man is more valuable if he has expressed it\n",
    "            less compared to others (briefly, in binary data it must\n",
    "            be nice).\n",
    "        :param big_data: set true if want to multiply QR-decomposition\n",
    "            for items' similarities matrix (only for big data's)\n",
    "        \"\"\"\n",
    "        if via_normalize:\n",
    "            self.sparse_matrix = self.sparse_matrix.astype(np.float32)\n",
    "            # get l2-norm of rows\n",
    "            magnitude = np.sqrt(self.sparse_matrix.power(2).sum(axis=1))\n",
    "\n",
    "            # divide each row to it's l2-norm\n",
    "            for i in range(magnitude.shape[0]):\n",
    "                from_i = self.sparse_matrix.indptr[i]\n",
    "                to_i = self.sparse_matrix.indptr[i + 1]\n",
    "                self.sparse_matrix.data[from_i:to_i] = (\n",
    "                        self.sparse_matrix.data[from_i:to_i] / magnitude[i][0]\n",
    "                )\n",
    "        # count cosine similarity matrix\n",
    "        self.similarities = cosine_similarity(self.sparse_matrix.transpose())\n",
    "\n",
    "        if big_data:\n",
    "            self.sim_q, self.sim_r = np.linalg.qr(self.similarities)\n",
    "\n",
    "            # counting how all users relates to all items\n",
    "            self.recommendations = (self.sim_q @ (self.sim_r @ self.sparse_matrix.T))\n",
    "        else:\n",
    "            self.recommendations = (self.similarities @ self.sparse_matrix.T)\n",
    "        # compared to max l1-norm of exact item's vector\n",
    "        self.recommendations /= np.array([np.abs(self.similarities).sum(axis=1)]).T\n",
    "\n",
    "        # remove from our answer set already liked by users items\n",
    "        for user_id in range(self.sparse_matrix.shape[0]):\n",
    "            for i in range(self.sparse_matrix.indptr[user_id],\n",
    "                           self.sparse_matrix.indptr[user_id + 1]):\n",
    "                self.recommendations[self.sparse_matrix.indices[i], user_id] = 0\n",
    "        self.recommendations = np.argsort(-self.recommendations.T, axis=1)[:, :self.fast_reqs_limit]\n",
    "\n",
    "    def find_similar_item(self,\n",
    "                          item,\n",
    "                          res_n: int = 10):\n",
    "        \"\"\"\n",
    "        :param item: item as it is stored in database\n",
    "            (meant it is in column that was given to load)\n",
    "        :param res_n: count of items to find\n",
    "        :return: `res_n` most similar to `item` items\n",
    "        \"\"\"\n",
    "        item_id = self._item2index(item)\n",
    "        # get vector corresponding to item\n",
    "        item_vec = self.similarities[item_id].reshape(1, -1)[0]\n",
    "        # choose top `res_n` and return them\n",
    "        return self._index2item(np.argsort(item_vec)[::-1][1:res_n + 1])\n",
    "\n",
    "    def recommend_to_user(self,\n",
    "                          user,\n",
    "                          res_n: int = 10):\n",
    "        \"\"\"\n",
    "        :param user: user as it is stored in database\n",
    "            (meant it is in column that was given to load)\n",
    "        :param res_n: count of items to recommend\n",
    "        :return: `res_n` most suitable (by RS) items for `user`\n",
    "        \"\"\"\n",
    "        user_id = self._user2index(user)\n",
    "\n",
    "        # counting how our user relates to all items\n",
    "        if self.sim_q is None:\n",
    "            scores_vec = (self.similarities @ self.sparse_matrix[user_id, :].T)\n",
    "        else:\n",
    "            scores_vec = (self.sim_q @ (self.sim_r @ self.sparse_matrix[user_id, :].T))\n",
    "        # compared to max l1-norm of exact item's vector\n",
    "        scores_vec /= np.array([np.abs(self.similarities).sum(axis=1)]).T\n",
    "\n",
    "        # remove from our answer set already liked by user items\n",
    "        for i in range(self.sparse_matrix.indptr[user_id],\n",
    "                       self.sparse_matrix.indptr[user_id + 1]):\n",
    "            scores_vec[self.sparse_matrix.indices[i], 0] = 0\n",
    "\n",
    "        # choose top `res_n` and return them\n",
    "        return self._index2item(np.argsort(scores_vec.T)[0][::-1][:res_n])\n",
    "\n",
    "    def fast_recommend(self,\n",
    "                       user,\n",
    "                       res_n: int = 10):\n",
    "        \"\"\"\n",
    "        :param user: user as it is stored in database\n",
    "            (meant it is in column that was given to load)\n",
    "        :param res_n: count of items to recommend\n",
    "        :return: `res_n` most suitable (by RS) items for `user`\n",
    "        \"\"\"\n",
    "        user_id = self._user2index(user)\n",
    "        rec_vector = self.recommendations[user_id, :]\n",
    "        return self._index2item(rec_vector[:res_n])\n",
    "\n",
    "    def drop_slow(self):\n",
    "        \"\"\"\n",
    "        delete all heavy object attrs that are not used in\n",
    "        fast_recommend method\n",
    "        \"\"\"\n",
    "        del self.similarities\n",
    "        del self.sim_r\n",
    "        del self.sim_q\n",
    "        del self.sparse_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "99c53428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape:\t 285 x 285\n"
     ]
    }
   ],
   "source": [
    "complement_items = ComplementItemRS()\n",
    "complement_items.load(\"../small_data/lastfm2collab.csv\", [\"user_id\", \"item_id\"])\n",
    "complement_items.build(False, True)\n",
    "n, m = complement_items.similarities.shape\n",
    "print(\"shape:\\t\", n, 'x', m)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6fa84f8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "similar items:\t ['limp bizkit', 'billy talent', 'papa roach', 'evanescence', 'sum 41', 'bullet for my valentine', 'three days grace', 'red hot chili peppers', 'avril lavigne', 'rise against']\n",
      "recommend items:\t ['joy division', 'david bowie', 'the smiths', 'the rolling stones', 'tom waits', 'elliott smith', 'eric clapton', 'the clash', 'belle and sebastian', 'yann tiersen']\n",
      "fast recommend items:\t ['joy division', 'david bowie', 'the smiths', 'the rolling stones', 'tom waits', 'elliott smith', 'eric clapton', 'the clash', 'belle and sebastian', 'yann tiersen']\n"
     ]
    }
   ],
   "source": [
    "print(\"similar items:\\t\", complement_items.find_similar_item(\"linkin park\"))\n",
    "print(\"recommend items:\\t\", complement_items.recommend_to_user(5985))\n",
    "complement_items.drop_slow()\n",
    "print(\"fast recommend items:\\t\", complement_items.fast_recommend(5985))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d805b3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_ids = []\n",
    "movie_ids = []\n",
    "ratings = []\n",
    "with zipfile.ZipFile('data/ml-10m.zip') as archive:\n",
    "    with archive.open('ml-10M100K/ratings.dat') as f:\n",
    "        for l in f:\n",
    "            user, movie, rating, _ = l.split(b'::')\n",
    "            user_ids.append(int(user) - 1)\n",
    "            movie_ids.append(int(movie) - 1)\n",
    "            ratings.append(float(rating))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e09b74fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (71567, 65133)\n",
      "Ratio of nonzero elements: 0.0010738646228571796\n"
     ]
    }
   ],
   "source": [
    "A = csr_matrix((np.array(ratings) >= 4, (user_ids, movie_ids)), dtype=np.float32)\n",
    "A.eliminate_zeros()\n",
    "print(\"Shape:\", A.shape)\n",
    "print(\"Ratio of nonzero elements:\", A.nnz / (A.shape[0] * A.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "54ece5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_users, n_movies = A.shape\n",
    "n_test = int(n_users * 0.2)\n",
    "n_train = n_users - n_test\n",
    "idx = np.arange(n_users)\n",
    "np.random.shuffle(idx)\n",
    "test_idx, train_idx = idx[:n_test], idx[n_test:]\n",
    "A_test, A_train = A[test_idx,:], A[train_idx,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2a91c99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend(sparse_matrix, pred_am, similarities):\n",
    "    \"\"\"\n",
    "        Input\n",
    "            score_mat: sparse batch_size x n_movies array\n",
    "            pred_am: requested number of recommendations\n",
    "            V: 2D numpy array (n_movies x rank)\n",
    "            \n",
    "        Output\n",
    "            recs: batch_size x pred_am array of movies to recommend, with descending predicted rating\n",
    "    \"\"\"\n",
    "    recommendations = similarities.transpose() @ (similarities @ sparse_matrix.T)\n",
    "    print(recommendations.shape, similarities.shape)\n",
    "    return np.argsort(-recommendations.T, axis=1)[:, :pred_am]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "82985c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(A_test, pred_am, mat, batch_size=500):\n",
    "    \"\"\"\n",
    "        Input\n",
    "            A_test: sparse n_test x n_movies array corresponding to new users\n",
    "            pred_am: requested number of recommendations\n",
    "            V: 2D numpy array representing the rating model\n",
    "            batch_size: number of users to build recommendations for in a single call to recommend\n",
    "\n",
    "        Output\n",
    "            hit_idx: list of n_test ints: place of secret movie \n",
    "                     in top-pred_am recommendations (or pred_am if it is missing)\n",
    "    \"\"\"\n",
    "    secrets = []\n",
    "    nonempty_users = []\n",
    "    A_test = A_test.copy()\n",
    "    for user in range(A_test.shape[0]):\n",
    "        _, good, _ = find(A_test[user,:])\n",
    "        if len(good) == 0:\n",
    "            continue\n",
    "        nonempty_users.append(user)\n",
    "        secret = np.random.choice(good, 1)[0]\n",
    "        A_test[user, secret] = 0\n",
    "        secrets.append(secret)\n",
    "    hit_idx = []\n",
    "    for i in range(0, len(nonempty_users), batch_size):\n",
    "        print(f\"bench num#{i}\")\n",
    "        # Build recomendations for a batch.\n",
    "        recommendations = recommend(A_test[nonempty_users[i:i + batch_size], :], pred_am + 1, mat)\n",
    "        # Place secret in the last column so that the following .argmax finds it.\n",
    "        recommendations[:,-1] = secrets[i: i + batch_size]\n",
    "        # Find secret among the recommendations and place its index into batch_hit_idx.\n",
    "        batch_hit_idx = (recommendations == np.array([secrets[i:i + batch_size]]).T).argmax(1)\n",
    "        hit_idx += batch_hit_idx.tolist()\n",
    "    return hit_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1fd99ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hit_rates(A_test, pred_ams, mat):\n",
    "    \"\"\"\n",
    "        Input\n",
    "            A_test: sparse n_test x n_movies array corresponding to new users \n",
    "            pred_ams: list of ints: number of top recomendations to evaluate hit rate for\n",
    "            V: 2D numpy array representing the rating model\n",
    "        Output\n",
    "            hit_rates: list of float: hit rate for each element of n_recs\n",
    "    \"\"\"\n",
    "    hit_idx = evaluate_model(A_test, max(pred_ams), mat)\n",
    "    hit_rates = []\n",
    "    for pred_am in pred_ams:\n",
    "        hit_rates.append(sum(map(lambda x: int(x < pred_am), hit_idx)) / len(hit_idx))\n",
    "    return hit_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f951c646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bench num#0\n",
      "(65133, 500) (10, 65133)\n",
      "bench num#500\n",
      "(65133, 465) (10, 65133)\n",
      "hitrate:\t 0.11088082901554404\n",
      "bench num#0\n",
      "(65133, 500) (10, 65133)\n",
      "bench num#500\n",
      "(65133, 465) (10, 65133)\n",
      "hitrate:\t 0.11295336787564766\n",
      "bench num#0\n",
      "(65133, 500) (10, 65133)\n",
      "bench num#500\n",
      "(65133, 465) (10, 65133)\n",
      "hitrate:\t 0.13471502590673576\n"
     ]
    }
   ],
   "source": [
    "rank = 10\n",
    "_, _, VT_svd = svds(A_train[:1000, :], k=rank)\n",
    "print(\"hitrates:\\t\", *get_hit_rates(A_test[:1000, :], [10], VT_svd))\n",
    "print(\"hitrates:\\t\", *get_hit_rates(A_test[:1000, :], [10], VT_svd))\n",
    "print(\"hitrates:\\t\", *get_hit_rates(A_test[:1000, :], [10], VT_svd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8e5e65e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_slow(sparse_matrix, pred_am, U, S, Vt):\n",
    "    \"\"\"\n",
    "        Input\n",
    "            score_mat: sparse batch_size x n_movies array\n",
    "            pred_am: requested number of recommendations\n",
    "            V: 2D numpy array (n_movies x rank)\n",
    "            \n",
    "        Output\n",
    "            recs: batch_size x pred_am array of movies to recommend, with descending predicted rating\n",
    "    \"\"\"\n",
    "    recommendations = ((np.multiply(Vt.T, S)) @ ((U.T @ U) @ (np.array([S]).T * (Vt @ sparse_matrix.T))))\n",
    "    return np.argsort(-recommendations.T, axis=1)[:, :pred_am]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "49694a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_slow(A_test, pred_am, U, S, Vt, batch_size=500):\n",
    "    \"\"\"\n",
    "        Input\n",
    "            A_test: sparse n_test x n_movies array corresponding to new users\n",
    "            pred_am: requested number of recommendations\n",
    "            V: 2D numpy array representing the rating model\n",
    "            batch_size: number of users to build recommendations for in a single call to recommend\n",
    "\n",
    "        Output\n",
    "            hit_idx: list of n_test ints: place of secret movie \n",
    "                     in top-pred_am recommendations (or pred_am if it is missing)\n",
    "    \"\"\"\n",
    "    secrets = []\n",
    "    nonempty_users = []\n",
    "    A_test = A_test.copy()\n",
    "    for user in range(A_test.shape[0]):\n",
    "        _, good, _ = find(A_test[user,:])\n",
    "        if len(good) == 0:\n",
    "            continue\n",
    "        nonempty_users.append(user)\n",
    "        secret = np.random.choice(good, 1)[0]\n",
    "        A_test[user, secret] = 0\n",
    "        secrets.append(secret)\n",
    "    hit_idx = []\n",
    "    for i in range(0, len(nonempty_users), batch_size):\n",
    "        print(f\"bench num#{i}\")\n",
    "        # Build recomendations for a batch.\n",
    "        recommendations = recommend_slow(A_test[nonempty_users[i:i + batch_size], :], pred_am + 1, U, S, Vt)\n",
    "        # Place secret in the last column so that the following .argmax finds it.\n",
    "        recommendations[:,-1] = secrets[i: i + batch_size]\n",
    "        # Find secret among the recommendations and place its index into batch_hit_idx.\n",
    "        batch_hit_idx = (recommendations == np.array([secrets[i:i + batch_size]]).T).argmax(1)\n",
    "        hit_idx += batch_hit_idx.tolist()\n",
    "    return hit_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d37cd0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hit_rates_slow(A_test, pred_ams, U, S, Vt):\n",
    "    \"\"\"\n",
    "        Input\n",
    "            A_test: sparse n_test x n_movies array corresponding to new users \n",
    "            pred_ams: list of ints: number of top recomendations to evaluate hit rate for\n",
    "            V: 2D numpy array representing the rating model\n",
    "        Output\n",
    "            hit_rates: list of float: hit rate for each element of n_recs\n",
    "    \"\"\"\n",
    "    hit_idx = evaluate_model_slow(A_test, max(pred_ams), U, S, Vt)\n",
    "    hit_rates = []\n",
    "    for pred_am in pred_ams:\n",
    "        hit_rates.append(sum(map(lambda x: int(x < pred_am), hit_idx)) / len(hit_idx))\n",
    "    return hit_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e6ed52b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bench num#0\n",
      "(1000, 10) (10,) (10, 65133) (65133, 500)\n",
      "bench num#500\n",
      "(1000, 10) (10,) (10, 65133) (65133, 465)\n",
      "hitrates for 10/20/30:\t 0.08911917098445596 0.15751295336787566 0.19170984455958548\n",
      "bench num#0\n",
      "(1000, 10) (10,) (10, 65133) (65133, 500)\n",
      "bench num#500\n",
      "(1000, 10) (10,) (10, 65133) (65133, 465)\n",
      "hitrates for 10/20/30:\t 0.09015544041450778 0.1461139896373057 0.19792746113989637\n",
      "bench num#0\n",
      "(1000, 10) (10,) (10, 65133) (65133, 500)\n",
      "bench num#500\n",
      "(1000, 10) (10,) (10, 65133) (65133, 465)\n",
      "hitrates for 10/20/30:\t 0.11606217616580311 0.18652849740932642 0.23316062176165803\n"
     ]
    }
   ],
   "source": [
    "rank = 10\n",
    "U, S, Vt = svds(A_train[:1000, :], k=rank)\n",
    "print(\"hitrates for 10/20/30:\\t\", *get_hit_rates_slow(A_test[:1000, :], [10, 20, 30], U, S, Vt))\n",
    "print(\"hitrates for 10/20/30:\\t\", *get_hit_rates_slow(A_test[:1000, :], [10, 20, 30], U, S, Vt))\n",
    "print(\"hitrates for 10/20/30:\\t\", *get_hit_rates_slow(A_test[:1000, :], [10, 20, 30], U, S, Vt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae8a620",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
