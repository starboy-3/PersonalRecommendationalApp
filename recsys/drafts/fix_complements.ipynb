{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a978b014",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "import re\n",
    "import string\n",
    "\n",
    "import numpy as np\n",
    "import scipy.sparse as sparse   \n",
    "from pandas import read_csv\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from nltk.stem.snowball import SnowballStemmer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dfc9a222",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StemmerWrapper:\n",
    "    \"\"\" Class wrapper to some language stemmer; Via wrapping, I think,\n",
    "        it is comfortable to operate with stemmer and functions,\n",
    "        that formats text for systems.\n",
    "    \"\"\"\n",
    "    def __init__(self, lang=\"russian\"):\n",
    "        \"\"\"\n",
    "        :param lang: Initializing stemmer with setting `lang` language\n",
    "        \"\"\"\n",
    "        self.stemmer = SnowballStemmer(lang)\n",
    "\n",
    "    def stem(self, *args, **kwargs):\n",
    "        \"\"\" just for beauty and comfortable call\"\"\"\n",
    "        return self.stemmer.stem(*args, **kwargs)\n",
    "\n",
    "    @staticmethod\n",
    "    def clean_string(sample_s: str) -> str:\n",
    "        \"\"\"\n",
    "        :param sample_s: string to be formatted\n",
    "        :return: formatted string\n",
    "        formats given string by removing unnecessary components for\n",
    "        building recommendation systems\n",
    "        \"\"\"\n",
    "        # string to lowercase\n",
    "        sample_s = sample_s.strip().lower()\n",
    "        # removing one-symbol words\n",
    "        sample_s = re.sub(r'\\b[ЁёА-я]{1}\\b', '', sample_s)\n",
    "        # removing punctuation\n",
    "        sample_s = re.sub(r'[%s]' % re.escape(string.punctuation), ' ',\n",
    "                          sample_s)\n",
    "        # removing one-digit numbers\n",
    "        sample_s = re.sub(r'\\b[0-9]{1}\\b', '', sample_s)\n",
    "        # replacing several-in-a-row space symbols with only one space\n",
    "        sample_s = re.sub(r'\\s+', ' ', sample_s)\n",
    "        return sample_s.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc2ad076",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loader:\n",
    "    \"\"\"\n",
    "    Class represents data-loader for systems. This is a base-class,\n",
    "    so some virtual function must be overwritten.\n",
    "    \"\"\"\n",
    "    def __init__(self, stemmer):\n",
    "        \"\"\"\n",
    "        :param stemmer: language stemmer to be used\n",
    "        \"\"\"\n",
    "        self.stemmer = stemmer\n",
    "\n",
    "    def merge_contents(self,\n",
    "                       table: str,\n",
    "                       main_id: str,\n",
    "                       content_cname: str,\n",
    "                       columns: list):\n",
    "        \"\"\"\n",
    "        merges content of selected `columns` from `table`;\n",
    "        check overwritten function for more info.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    @staticmethod\n",
    "    def split_series(series):\n",
    "        \"\"\"\n",
    "        :return: (pd.core.series.Series) updated `series`-copy\n",
    "        :param series: (pd.core.series.Series)\n",
    "        Splitting values in cell's of column `series` (in-place)\n",
    "        \"\"\"\n",
    "        # handling None values separately\n",
    "        return series.apply(lambda x: x.split() if type(x) == str else [])\n",
    "\n",
    "    def format_columns(self,\n",
    "                       dataframe,\n",
    "                       main_id_cname: str,\n",
    "                       content_cname: str,\n",
    "                       columns: list):\n",
    "        \"\"\"\n",
    "        :param dataframe: contains data to be formatted and used\n",
    "        :param main_id_cname: item-representing-column's name\n",
    "        :param content_cname: content-representing-column's name\n",
    "        :param columns: names of columns in dataframe\n",
    "        :return: 2-column dataframe, named as main_id_cname and\n",
    "            content_cname; second columns contains formatted\n",
    "            and merged `columns` content\n",
    "        \"\"\"\n",
    "        # initializing new column in dataframe with empty strings\n",
    "        dataframe[content_cname] = ''\n",
    "\n",
    "        # remember items-id-representing column\n",
    "        id_series = dataframe[main_id_cname]\n",
    "\n",
    "        # set dataframe to a `columns`-containing table,\n",
    "        # where all string infos was split into lists\n",
    "        dataframe = dataframe[[content_cname] + columns].apply(\n",
    "                self.split_series)\n",
    "\n",
    "        # formatting all rows\n",
    "        # firstly, we put add all lists to content containing column\n",
    "        dataframe[content_cname] = reduce(\n",
    "                lambda prev, el: prev + dataframe[el],\n",
    "                columns,\n",
    "                dataframe[content_cname]\n",
    "        ).apply(  # then we would stem all words in this column\n",
    "                lambda iterable: [self.stemmer.stem(w) for w in iterable]\n",
    "        ).apply(  # lastly, we join lists to string\n",
    "                lambda iterable: ' '.join(iterable)\n",
    "        ).apply(\n",
    "                StemmerWrapper.clean_string\n",
    "        )\n",
    "\n",
    "        # set item-representing-column's data\n",
    "        dataframe[main_id_cname] = id_series\n",
    "\n",
    "        # return table representing relationship item\n",
    "        return dataframe[[main_id_cname, content_cname]]\n",
    "\n",
    "    def parse(self, table: str, columns: list):\n",
    "        \"\"\"\n",
    "        parses selected `columns` from `table`;\n",
    "        check overwritten function for more info.\n",
    "        \"\"\"\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d113db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CsvLoader(Loader):\n",
    "    \"\"\"\n",
    "    Represents data-loader from csv-file\n",
    "    \"\"\"\n",
    "    def __init__(self, stemmer):\n",
    "        \"\"\"\n",
    "        :param stemmer: language stemmer to be used\n",
    "        \"\"\"\n",
    "        super().__init__(stemmer)\n",
    "\n",
    "    def merge_contents(self,\n",
    "                       path: str,\n",
    "                       main_id_cname: str,\n",
    "                       content_cname: str,\n",
    "                       columns: list):\n",
    "        \"\"\"\n",
    "        :param path: (str) path to table, where from data will be read\n",
    "        :param main_id_cname: (str) item-representing-column's name;\n",
    "            it is explicit for `path` to have such column\n",
    "        :param content_cname: (str) content-representing-column's name\n",
    "        :param columns: (list) columns containing main content,\n",
    "            that will be used to build a content-based model\n",
    "        :return: (pd.core.frame.DataFrame) 2-column dataframe\n",
    "            representing relationship of item and it's content\n",
    "            (one-to-one relationship)\n",
    "        \"\"\"\n",
    "        return self.format_columns(\n",
    "                self.parse(path, columns + [main_id_cname]),\n",
    "                main_id_cname,\n",
    "                content_cname,\n",
    "                columns\n",
    "        )\n",
    "\n",
    "    def parse(self, table: str, columns: list):\n",
    "        \"\"\"\n",
    "        :param table: database table name\n",
    "        :param columns: columns to be parsed\n",
    "        :return: dataframe with parsed columns\n",
    "        \"\"\"\n",
    "        return read_csv(\n",
    "                table,\n",
    "                skipinitialspace=True,\n",
    "                usecols=columns\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e363541",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecommendationSystem:\n",
    "    \"\"\"\n",
    "    Root-class representing recommendation system\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def load_and_build(self, *args):\n",
    "        pass\n",
    "\n",
    "    def load(self, *args):\n",
    "        pass\n",
    "\n",
    "    def build(self, *args):\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0ad95761",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CollaborativeFiltering(RecommendationSystem):\n",
    "    \"\"\"\n",
    "    TODO checkout and comment this class\n",
    "    Represents recommendation system based on collaborative-filtering\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(CollaborativeFiltering, self).__init__()\n",
    "        # sparse matrix of implicit user-item interactions\n",
    "        self.sparse_matrix = None\n",
    "        # users matrix in lower rank\n",
    "        self.users_matrix = None\n",
    "        # items matrix in lower rank\n",
    "        self.items_matrix = None\n",
    "\n",
    "        # dataframes, so we could map indices used in class\n",
    "        # methods with indices used in database\n",
    "        self.user_indices_decode = None\n",
    "        self.item_indices_decode = None\n",
    "\n",
    "        # column names in database corresponding to user and item\n",
    "        self.user_cname = None\n",
    "        self.item_cname = None\n",
    "\n",
    "    def load(self,\n",
    "             table: str,\n",
    "             columns: list,\n",
    "             loader_type: str = \"csv\",\n",
    "             connection=None):\n",
    "        if len(columns) < 2 or len(columns) > 3:\n",
    "            raise RuntimeError(\"CollaborativeFiltering::load: columns \"\n",
    "                               \"argument must contain exactly 3 \"\n",
    "                               \"string-values\")\n",
    "\n",
    "        # initialize loader\n",
    "        if loader_type == \"csv\":\n",
    "            loader = CsvLoader(None)\n",
    "        elif loader_type == \"db\":\n",
    "            if connection is None:\n",
    "                raise RuntimeError(\"CollaborativeFiltering::load: received \"\n",
    "                                   \"connection equals to None with a \"\n",
    "                                   \"loader_type equals db\")\n",
    "            loader = DataBaseLoader(None, connection)\n",
    "        else:\n",
    "            raise RuntimeError(\"CollaborativeFiltering::load: no loader \"\n",
    "                               \"available for given loader_type\")\n",
    "\n",
    "        # load implicit data in 3-column dataframe\n",
    "        dataframe = loader.parse(table, columns)\n",
    "        dataframe.dropna(inplace=True)\n",
    "        \n",
    "        relations_count = dataframe.shape[0]\n",
    "        # copying column names explicitly\n",
    "        self.user_cname, self.item_cname = columns[0] + \"\", columns[1] + \"\"\n",
    "        user_id_cname, item_id_cname = columns[0] + \"_id\", columns[1] + \"_id\"\n",
    "\n",
    "        # save user and item columns, so we will be able to return to\n",
    "        # caller recommendation as it is stored in database\n",
    "        dataframe[user_id_cname] = dataframe[columns[0]].astype(\n",
    "                \"category\").cat.codes\n",
    "        dataframe[item_id_cname] = dataframe[columns[1]].astype(\n",
    "                \"category\").cat.codes\n",
    "        self.user_indices_decode = dataframe[\n",
    "            [user_id_cname, columns[0]]].drop_duplicates()\n",
    "        self.item_indices_decode = dataframe[\n",
    "            [item_id_cname, columns[1]]].drop_duplicates()\n",
    "        dataframe.drop(columns[:2], axis=1, inplace=True)\n",
    "\n",
    "        # initializing sparse matrix\n",
    "        users = dataframe[user_id_cname].astype(int)\n",
    "        items = dataframe[item_id_cname].astype(int)\n",
    "        users_count = len(dataframe[user_id_cname].unique())\n",
    "        items_count = len(dataframe[item_id_cname].unique())\n",
    "        if len(columns) == 3:\n",
    "            self.sparse_matrix = sparse.csr_matrix(\n",
    "                    (dataframe[columns[2]], (users, items)),\n",
    "                    shape=(users_count, items_count)\n",
    "            )\n",
    "        elif len(columns) == 2:\n",
    "            self.sparse_matrix = sparse.csr_matrix(\n",
    "                    ([1 for _ in range(relations_count)], (users, items)),\n",
    "                    shape=(users_count, items_count)\n",
    "            )\n",
    "\n",
    "    def item2index(self,\n",
    "                   item):\n",
    "        \"\"\"\n",
    "        :param item: item as it is stored in database\n",
    "        :return: index used in this object for `item`\n",
    "        \"\"\"\n",
    "        return self.item_indices_decode[\n",
    "            self.item_cname + \"_id\"\n",
    "            ].loc[self.item_indices_decode[self.item_cname] == item].iloc[0]\n",
    "\n",
    "    def user2index(self,\n",
    "                   user):\n",
    "        \"\"\"\n",
    "        :param user: user as it is stored in database\n",
    "        :return: index used in this object for `user`\n",
    "        \"\"\"\n",
    "        return self.user_indices_decode[\n",
    "            self.user_cname + \"_id\"\n",
    "            ].loc[self.user_indices_decode[self.user_cname] == user].iloc[0]\n",
    "\n",
    "    def index2item(self,\n",
    "                   items_ids: list):\n",
    "        \"\"\"\n",
    "        :param items_ids: list of indices as they are stored in this\n",
    "            object\n",
    "        :return: corresponding to `indices` values of items\n",
    "        \"\"\"\n",
    "        result = list()\n",
    "        for item_id in items_ids:\n",
    "            result.append(\n",
    "                    self.item_indices_decode[\n",
    "                        self.item_cname\n",
    "                    ].loc[\n",
    "                        self.item_indices_decode[\n",
    "                            self.item_cname + \"_id\"] == item_id\n",
    "                        ].iloc[0]\n",
    "            )\n",
    "        return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "1f2d0c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ComplementItemRS(CollaborativeFiltering):\n",
    "    \"\"\"\n",
    "    COMPLEMENTARY ITEM\n",
    "    collaborative user-based filtering recommendation system\n",
    "    to find item that is frequently being consumed with some item\n",
    "\n",
    "    будет точь-в-точь complementary, если матрица будет строиться\n",
    "    по отношениям order-item, где order-item = 1, если item\n",
    "    был в order, иначе 0.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(ComplementItemRS, self).__init__()\n",
    "        # sparse matrix of implicit user-item interactions\n",
    "        self.sparse_matrix = None\n",
    "\n",
    "        # dataframes, so we could map indices used in class\n",
    "        # methods with indices used in database\n",
    "        self.user_indices_decode = None\n",
    "        self.item_indices_decode = None\n",
    "\n",
    "        # column names in database corresponding to user and item\n",
    "        self.user_cname = None\n",
    "        self.item_cname = None\n",
    "\n",
    "        self.df_data = None\n",
    "        self.similarities = None\n",
    "\n",
    "    def build(self, via_normalize: bool = False):\n",
    "        if via_normalize:\n",
    "            self.sparse_matrix = self.sparse_matrix.astype(np.float32)\n",
    "            magnitude = np.sqrt(self.sparse_matrix.power(2).sum(axis=1))\n",
    "            for i in range(magnitude.shape[0]):\n",
    "                self.sparse_matrix.data[self.sparse_matrix.indptr[i]:\n",
    "                                        self.sparse_matrix.indptr[i + 1]] = self.sparse_matrix.data[\n",
    "                    self.sparse_matrix.indptr[i]:\n",
    "                                        self.sparse_matrix.indptr[i + 1]] / magnitude[i][0]\n",
    "        self.similarities = cosine_similarity(self.sparse_matrix.transpose())\n",
    "\n",
    "    def find_similar_item(self,\n",
    "                          item,\n",
    "                          res_n: int = 10):\n",
    "        item_id = self.item2index(item)\n",
    "        item_vec = self.similarities[item_id].reshape(1, -1)[0]\n",
    "        return self.index2item(np.argsort(item_vec)[::-1][1:res_n + 1])\n",
    "\n",
    "    def recommend_to_user(self,\n",
    "                          user: str,\n",
    "                          res_n: int = 10):\n",
    "        \"\"\" если хотим recommend for this order, то user (здесь это order)\n",
    "            должен быть пустым; для лучше работы нужен метод update или тп\n",
    "        \"\"\"\n",
    "        user_id = self.user2index(user)\n",
    "\n",
    "        scores_vec = (self.similarities @ self.sparse_matrix[user_id, :].T)\n",
    "        scores_vec /= np.array([np.abs(self.similarities).sum(axis=1)]).T\n",
    "        non_zero_c = 0\n",
    "        for i in range(self.sparse_matrix.indptr[user_id],\n",
    "                       self.sparse_matrix.indptr[user_id + 1]):\n",
    "            scores_vec[self.sparse_matrix.indices[i], 0] = 0\n",
    "        return self.index2item(np.argsort(scores_vec.T)[0][::-1][:res_n])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "99c53428",
   "metadata": {},
   "outputs": [],
   "source": [
    "complement_items = ComplementItemRS()\n",
    "complement_items.load(\"formatted_data/lastfm2collab.csv\", [\"user_id\", \"item_id\"])\n",
    "complement_items.build(True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "c9559118",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(285, 285)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complement_items.similarities.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "07bb8520",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 285)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complement_items.sparse_matrix.power(2).sum(axis=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "8877469d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['limp bizkit',\n",
       " 'three days grace',\n",
       " 'simple plan',\n",
       " 'bullet for my valentine',\n",
       " 'billy talent',\n",
       " 'breaking benjamin',\n",
       " 'papa roach',\n",
       " 'evanescence',\n",
       " 'rise against',\n",
       " 'foo fighters']"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complement_items.find_similar_item(\"linkin park\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "be133f14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['joy division',\n",
       " 'the smiths',\n",
       " 'david bowie',\n",
       " 'yann tiersen',\n",
       " 'the rolling stones',\n",
       " 'tom waits',\n",
       " 'eric clapton',\n",
       " 'misfits',\n",
       " 'led zeppelin',\n",
       " 'belle and sebastian']"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complement_items.recommend_to_user(5985)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "f5ffcd5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['joy division',\n",
       " 'the smiths',\n",
       " 'david bowie',\n",
       " 'yann tiersen',\n",
       " 'the rolling stones',\n",
       " 'tom waits',\n",
       " 'eric clapton',\n",
       " 'misfits',\n",
       " 'led zeppelin',\n",
       " 'belle and sebastian']"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complement_items.recommend_to_user(5985)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
