{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14606ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "import re\n",
    "import string\n",
    "\n",
    "import numpy as np\n",
    "import scipy.sparse as sparse   \n",
    "from pandas import read_csv\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from sklearn.preprocessing import MinMaxScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1422f5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StemmerWrapper:\n",
    "    \"\"\" Class wrapper to some language stemmer; Via wrapping, I think,\n",
    "        it is comfortable to operate with stemmer and functions,\n",
    "        that formats text for systems.\n",
    "    \"\"\"\n",
    "    def __init__(self, lang=\"russian\"):\n",
    "        \"\"\"\n",
    "        :param lang: Initializing stemmer with setting `lang` language\n",
    "        \"\"\"\n",
    "        self.stemmer = SnowballStemmer(lang)\n",
    "\n",
    "    def stem(self, *args, **kwargs):\n",
    "        \"\"\" just for beauty and comfortable call\"\"\"\n",
    "        return self.stemmer.stem(*args, **kwargs)\n",
    "\n",
    "    @staticmethod\n",
    "    def clean_string(sample_s: str) -> str:\n",
    "        \"\"\"\n",
    "        :param sample_s: string to be formatted\n",
    "        :return: formatted string\n",
    "        formats given string by removing unnecessary components for\n",
    "        building recommendation systems\n",
    "        \"\"\"\n",
    "        # string to lowercase\n",
    "        sample_s = sample_s.strip().lower()\n",
    "        # removing one-symbol words\n",
    "        sample_s = re.sub(r'\\b[ЁёА-я]{1}\\b', '', sample_s)\n",
    "        # removing punctuation\n",
    "        sample_s = re.sub(r'[%s]' % re.escape(string.punctuation), ' ',\n",
    "                          sample_s)\n",
    "        # removing one-digit numbers\n",
    "        sample_s = re.sub(r'\\b[0-9]{1}\\b', '', sample_s)\n",
    "        # replacing several-in-a-row space symbols with only one space\n",
    "        sample_s = re.sub(r'\\s+', ' ', sample_s)\n",
    "        return sample_s.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77e3cc9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loader:\n",
    "    \"\"\"\n",
    "    Class represents data-loader for systems. This is a base-class,\n",
    "    so some virtual function must be overwritten.\n",
    "    \"\"\"\n",
    "    def __init__(self, stemmer):\n",
    "        \"\"\"\n",
    "        :param stemmer: language stemmer to be used\n",
    "        \"\"\"\n",
    "        self.stemmer = stemmer\n",
    "\n",
    "    def merge_contents(self,\n",
    "                       table: str,\n",
    "                       main_id: str,\n",
    "                       content_cname: str,\n",
    "                       columns: list):\n",
    "        \"\"\"\n",
    "        merges content of selected `columns` from `table`;\n",
    "        check overwritten function for more info.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    @staticmethod\n",
    "    def split_series(series):\n",
    "        \"\"\"\n",
    "        :return: (pd.core.series.Series) updated `series`-copy\n",
    "        :param series: (pd.core.series.Series)\n",
    "        Splitting values in cell's of column `series` (in-place)\n",
    "        \"\"\"\n",
    "        # handling None values separately\n",
    "        return series.apply(lambda x: x.split() if type(x) == str else [])\n",
    "\n",
    "    def format_columns(self,\n",
    "                       dataframe,\n",
    "                       main_id_cname: str,\n",
    "                       content_cname: str,\n",
    "                       columns: list):\n",
    "        \"\"\"\n",
    "        :param dataframe: contains data to be formatted and used\n",
    "        :param main_id_cname: item-representing-column's name\n",
    "        :param content_cname: content-representing-column's name\n",
    "        :param columns: names of columns in dataframe\n",
    "        :return: 2-column dataframe, named as main_id_cname and\n",
    "            content_cname; second columns contains formatted\n",
    "            and merged `columns` content\n",
    "        \"\"\"\n",
    "        # initializing new column in dataframe with empty strings\n",
    "        dataframe[content_cname] = ''\n",
    "\n",
    "        # remember items-id-representing column\n",
    "        id_series = dataframe[main_id_cname]\n",
    "\n",
    "        # set dataframe to a `columns`-containing table,\n",
    "        # where all string infos was split into lists\n",
    "        dataframe = dataframe[[content_cname] + columns].apply(\n",
    "                self.split_series)\n",
    "\n",
    "        # formatting all rows\n",
    "        # firstly, we put add all lists to content containing column\n",
    "        dataframe[content_cname] = reduce(\n",
    "                lambda prev, el: prev + dataframe[el],\n",
    "                columns,\n",
    "                dataframe[content_cname]\n",
    "        ).apply(  # then we would stem all words in this column\n",
    "                lambda iterable: [self.stemmer.stem(w) for w in iterable]\n",
    "        ).apply(  # lastly, we join lists to string\n",
    "                lambda iterable: ' '.join(iterable)\n",
    "        ).apply(\n",
    "                StemmerWrapper.clean_string\n",
    "        )\n",
    "\n",
    "        # set item-representing-column's data\n",
    "        dataframe[main_id_cname] = id_series\n",
    "\n",
    "        # return table representing relationship item\n",
    "        return dataframe[[main_id_cname, content_cname]]\n",
    "\n",
    "    def parse(self, table: str, columns: list):\n",
    "        \"\"\"\n",
    "        parses selected `columns` from `table`;\n",
    "        check overwritten function for more info.\n",
    "        \"\"\"\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fbe6f186",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CsvLoader(Loader):\n",
    "    \"\"\"\n",
    "    Represents data-loader from csv-file\n",
    "    \"\"\"\n",
    "    def __init__(self, stemmer):\n",
    "        \"\"\"\n",
    "        :param stemmer: language stemmer to be used\n",
    "        \"\"\"\n",
    "        super().__init__(stemmer)\n",
    "\n",
    "    def merge_contents(self,\n",
    "                       path: str,\n",
    "                       main_id_cname: str,\n",
    "                       content_cname: str,\n",
    "                       columns: list):\n",
    "        \"\"\"\n",
    "        :param path: (str) path to table, where from data will be read\n",
    "        :param main_id_cname: (str) item-representing-column's name;\n",
    "            it is explicit for `path` to have such column\n",
    "        :param content_cname: (str) content-representing-column's name\n",
    "        :param columns: (list) columns containing main content,\n",
    "            that will be used to build a content-based model\n",
    "        :return: (pd.core.frame.DataFrame) 2-column dataframe\n",
    "            representing relationship of item and it's content\n",
    "            (one-to-one relationship)\n",
    "        \"\"\"\n",
    "        return self.format_columns(\n",
    "                self.parse(path, columns + [main_id_cname]),\n",
    "                main_id_cname,\n",
    "                content_cname,\n",
    "                columns\n",
    "        )\n",
    "\n",
    "    def parse(self, table: str, columns: list):\n",
    "        \"\"\"\n",
    "        :param table: database table name\n",
    "        :param columns: columns to be parsed\n",
    "        :return: dataframe with parsed columns\n",
    "        \"\"\"\n",
    "        return read_csv(\n",
    "                table,\n",
    "                skipinitialspace=True,\n",
    "                usecols=columns\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c129f3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecommendationSystem:\n",
    "    \"\"\"\n",
    "    Root-class representing recommendation system\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def load_and_build(self, *args):\n",
    "        pass\n",
    "\n",
    "    def load(self, *args):\n",
    "        pass\n",
    "\n",
    "    def build(self, *args):\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dcf2fdc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CollaborativeFiltering(RecommendationSystem):\n",
    "    \"\"\"\n",
    "    TODO checkout and comment this class\n",
    "    Represents recommendation system based on collaborative-filtering\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(CollaborativeFiltering, self).__init__()\n",
    "        # sparse matrix of implicit user-item interactions\n",
    "        self.sparse_matrix = None\n",
    "        # users matrix in lower rank\n",
    "        self.users_matrix = None\n",
    "        # items matrix in lower rank\n",
    "        self.items_matrix = None\n",
    "\n",
    "        # dataframes, so we could map indices used in class\n",
    "        # methods with indices used in database\n",
    "        self.user_indices_decode = None\n",
    "        self.item_indices_decode = None\n",
    "\n",
    "        # column names in database corresponding to user and item\n",
    "        self.user_cname = None\n",
    "        self.item_cname = None\n",
    "\n",
    "    def load(self,\n",
    "             table: str,\n",
    "             columns: list,\n",
    "             loader_type: str = \"csv\",\n",
    "             connection=None):\n",
    "        if len(columns) < 2 or len(columns) > 3:\n",
    "            raise RuntimeError(\"CollaborativeFiltering::load: columns \"\n",
    "                               \"argument must contain exactly 3 \"\n",
    "                               \"string-values\")\n",
    "\n",
    "        # initialize loader\n",
    "        if loader_type == \"csv\":\n",
    "            loader = CsvLoader(None)\n",
    "        elif loader_type == \"db\":\n",
    "            if connection is None:\n",
    "                raise RuntimeError(\"CollaborativeFiltering::load: received \"\n",
    "                                   \"connection equals to None with a \"\n",
    "                                   \"loader_type equals db\")\n",
    "            loader = DataBaseLoader(None, connection)\n",
    "        else:\n",
    "            raise RuntimeError(\"CollaborativeFiltering::load: no loader \"\n",
    "                               \"available for given loader_type\")\n",
    "\n",
    "        # load implicit data in 3-column dataframe\n",
    "        dataframe = loader.parse(table, columns)\n",
    "        dataframe.dropna(inplace=True)\n",
    "        \n",
    "        relations_count = dataframe.shape[0]\n",
    "        # copying column names explicitly\n",
    "        self.user_cname, self.item_cname = columns[0] + \"\", columns[1] + \"\"\n",
    "        user_id_cname, item_id_cname = columns[0] + \"_id\", columns[1] + \"_id\"\n",
    "\n",
    "        # save user and item columns, so we will be able to return to\n",
    "        # caller recommendation as it is stored in database\n",
    "        dataframe[user_id_cname] = dataframe[columns[0]].astype(\n",
    "                \"category\").cat.codes\n",
    "        dataframe[item_id_cname] = dataframe[columns[1]].astype(\n",
    "                \"category\").cat.codes\n",
    "        self.user_indices_decode = dataframe[\n",
    "            [user_id_cname, columns[0]]].drop_duplicates()\n",
    "        self.item_indices_decode = dataframe[\n",
    "            [item_id_cname, columns[1]]].drop_duplicates()\n",
    "        dataframe.drop(columns[:2], axis=1, inplace=True)\n",
    "\n",
    "        # initializing sparse matrix\n",
    "        users = dataframe[user_id_cname].astype(int)\n",
    "        items = dataframe[item_id_cname].astype(int)\n",
    "        users_count = len(dataframe[user_id_cname].unique())\n",
    "        items_count = len(dataframe[item_id_cname].unique())\n",
    "        if len(columns) == 3:\n",
    "            self.sparse_matrix = sparse.csr_matrix(\n",
    "                    (dataframe[columns[2]], (users, items)),\n",
    "                    shape=(users_count, items_count)\n",
    "            )\n",
    "        elif len(columns) == 2:\n",
    "            self.sparse_matrix = sparse.csr_matrix(\n",
    "                    ([1 for _ in range(relations_count)], (users, items)),\n",
    "                    shape=(users_count, items_count)\n",
    "            )\n",
    "\n",
    "    def item2index(self,\n",
    "                   item):\n",
    "        \"\"\"\n",
    "        :param item: item as it is stored in database\n",
    "        :return: index used in this object for `item`\n",
    "        \"\"\"\n",
    "        return self.item_indices_decode[\n",
    "            self.item_cname + \"_id\"\n",
    "            ].loc[self.item_indices_decode[self.item_cname] == item].iloc[0]\n",
    "\n",
    "    def user2index(self,\n",
    "                   user):\n",
    "        \"\"\"\n",
    "        :param user: user as it is stored in database\n",
    "        :return: index used in this object for `user`\n",
    "        \"\"\"\n",
    "        return self.user_indices_decode[\n",
    "            self.user_cname + \"_id\"\n",
    "            ].loc[self.user_indices_decode[self.user_cname] == user].iloc[0]\n",
    "\n",
    "    def index2item(self,\n",
    "                   items_ids: list):\n",
    "        \"\"\"\n",
    "        :param items_ids: list of indices as they are stored in this\n",
    "            object\n",
    "        :return: corresponding to `indices` values of items\n",
    "        \"\"\"\n",
    "        result = list()\n",
    "        for item_id in items_ids:\n",
    "            result.append(\n",
    "                    self.item_indices_decode[\n",
    "                        self.item_cname\n",
    "                    ].loc[\n",
    "                        self.item_indices_decode[\n",
    "                            self.item_cname + \"_id\"] == item_id\n",
    "                        ].iloc[0]\n",
    "            )\n",
    "        return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2b92ae06",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImplicitRS(CollaborativeFiltering):\n",
    "    \"\"\"\n",
    "        Implementing collaborative-filtering recommendation system\n",
    "        on implicit data of user-item interactions.\n",
    "\n",
    "        Used algorithm: Implicit-ALS via Conjugate Gradient Method\n",
    "        (in each step, vector is minimized along a search direction)\n",
    "\n",
    "        Used materials:\n",
    "        - http://www.sze.hu/~gtakacs/download/recsys_2011_draft.pdf\n",
    "        - http://www.yifanhu.net/PUB/cf.pdf\n",
    "\n",
    "        Briefly, implicit data is going to be gathered by user's\n",
    "        behaviour on exact product. If he will visit product site-page,\n",
    "        we will assume, that he is interested in such kind of products\n",
    "        and will look for other users with similar interests to\n",
    "        make a recommendation. Otherwise, we will assume, that we\n",
    "        know nothing about users opinion on product and will construct\n",
    "        model with a some small positive value for this product.\n",
    "\n",
    "        In build method, we are asking for `rank`, `iter_count`,\n",
    "        `lambda_val` and `alpha` parameters.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(ImplicitRS, self).__init__()\n",
    "        # sparse matrix of implicit user-item interactions\n",
    "        self.sparse_matrix = None\n",
    "        # users matrix in lower rank\n",
    "        self.users_matrix = None\n",
    "        # items matrix in lower rank\n",
    "        self.items_matrix = None\n",
    "\n",
    "        # dataframes, so we could map indices used in class\n",
    "        # methods with indices used in database\n",
    "        self.user_indices_decode = None\n",
    "        self.item_indices_decode = None\n",
    "\n",
    "        # column names in database corresponding to user and item\n",
    "        self.user_cname = None\n",
    "        self.item_cname = None\n",
    "\n",
    "        # projecting [min, max) on range [0, 1) # not sure about\n",
    "        # boundary points\n",
    "        self.min_max_scaler = MinMaxScaler()\n",
    "\n",
    "    def build(self,\n",
    "              rank=20,\n",
    "              iter_count=25,\n",
    "              lambda_val=0.1,\n",
    "              alpha=40):\n",
    "        \"\"\"\n",
    "        :param rank: (int) aim-rank to user and item representing\n",
    "            matrices. We want A ~ U @ V,  where A (m x n) is our\n",
    "            sparse matrix of interactions, matrix U (m x rank)\n",
    "            represents users and matrix V (n x rank) represents items.\n",
    "        :param iter_count: (int) iterations count to build matrix\n",
    "        :param lambda_val: (double) parameter used in algo...\n",
    "        :param alpha: (double) parameter representing how strongly\n",
    "            we will be confident about the fact of interaction\n",
    "            between user and item\n",
    "        \"\"\"\n",
    "        self.implicit_als(rank, iter_count, lambda_val, alpha)\n",
    "\n",
    "    @staticmethod\n",
    "    def non_zeros_in_row(csr_matrix,\n",
    "                         row):\n",
    "        \"\"\"\n",
    "        :param csr_matrix: sparse matrix\n",
    "        :param row: row of sparse matrix\n",
    "        :return: range of tuples of 2 elements: index of column of\n",
    "            non-zero element in csr_matrix's row and value of non-zero\n",
    "            element itself\n",
    "        \"\"\"\n",
    "        for i in range(csr_matrix.indptr[row], csr_matrix.indptr[row + 1]):\n",
    "            yield csr_matrix.indices[i], csr_matrix.data[i]\n",
    "\n",
    "    def wrr(self,\n",
    "            init_vec,\n",
    "            a_mat,\n",
    "            r_vec,\n",
    "            c_mat,\n",
    "            item_mat,\n",
    "            u_id: int,\n",
    "            iter_count: int):\n",
    "        \"\"\"\n",
    "        Weighted Ridge Regression.\n",
    "        I accepted M (from algorithm) equals to identity matrix.\n",
    "        To understand what is going on in code below, take a look to\n",
    "        one of those two links in class declaration docstring above.\n",
    "        :param init_vec: vector w with which we are currently\n",
    "            working; we are minimizing with respect to this vector.\n",
    "        :param a_mat: matrix A from algorithm.\n",
    "        :param r_vec: difference between Aw and b.\n",
    "        :param c_mat: matrix representing confidence.\n",
    "        :param item_mat: matrix of items.\n",
    "        :param u_id: user's id of one whose vector we are formatting.\n",
    "        :param iter_count: count of iterations to be done.\n",
    "        :return: preconditioned conjugate gradient method for\n",
    "            solving Aw = b.\n",
    "        \"\"\"\n",
    "        p_vec = r_vec.copy()\n",
    "        gamma = r_vec.dot(r_vec)  # gamma = r^T z, where z = M^1 r\n",
    "        for _ in range(iter_count):\n",
    "            # find A\n",
    "            a_dot_p = a_mat @ p_vec\n",
    "            for it_id, conf in self.non_zeros_in_row(c_mat, u_id):\n",
    "                # TODO try without minus 1\n",
    "                a_dot_p += (conf - 1) * (\n",
    "                        item_mat[it_id] @ p_vec) * item_mat[it_id]\n",
    "\n",
    "            # updating w and r vectors\n",
    "            alpha = gamma / (p_vec @ a_dot_p)\n",
    "            init_vec += alpha * p_vec\n",
    "            r_vec -= alpha * a_dot_p\n",
    "\n",
    "            # below: p = z + beta p, beta = gamma / (r^T z)\n",
    "            tmp_gamma = r_vec.dot(r_vec)\n",
    "            p_vec = r_vec + (gamma / tmp_gamma) * p_vec\n",
    "            gamma = tmp_gamma\n",
    "        return init_vec\n",
    "\n",
    "    def least_squares(self,\n",
    "                      c_mat,\n",
    "                      user_mat,\n",
    "                      item_mat,\n",
    "                      lambda_val,\n",
    "                      iter_count=5):\n",
    "        \"\"\"\n",
    "        TODO try without UTU and VTV\n",
    "        We will to solve next equations for each u (user) and v (item):\n",
    "        (U.T @ U + lambda * I + U.T @ (C_v - I) @ U) @ v\n",
    "            = U.T @ C_v * interacted(v)\n",
    "        (V.T @ V + lambda * I + V.T @ (C_u - I) @ V) @ u\n",
    "            = V.T @ C_u * interacted(u)\n",
    "        with a conjugate gradient method, where\n",
    "        A = X.T @ U + lambda * I + U.T @ (C_v - I) @ U,\n",
    "        b = U.T @ C_v * interacted(v)\n",
    "        :param c_mat: mat represents confidence about u-i interactions\n",
    "            (by our definition, confidence_{ui} = 1 + alpha r_{ui})\n",
    "        :param user_mat: matrix of size m x rank, represents users\n",
    "        :param item_mat: matrix of size n x rank, represents items\n",
    "        :param lambda_val: non-negative regularization coefficient\n",
    "        :param iter_count: count of iterations to be done\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        users_count, rank = user_mat.shape\n",
    "\n",
    "        # matrix of size (r, r)\n",
    "        a_mat = item_mat.T @ item_mat + lambda_val * np.eye(rank)\n",
    "\n",
    "        for u_id in range(users_count):\n",
    "            # vector of size (r, )\n",
    "            w = user_mat[u_id]\n",
    "\n",
    "            # find r = b − Aw, vector of size (r, )\n",
    "            r_vec = -a_mat @ w\n",
    "            for it_id, conf in self.non_zeros_in_row(c_mat, u_id):\n",
    "                # TODO try without minus 1\n",
    "                r_vec += (conf - (conf - 1) *\n",
    "                          (item_mat[it_id] @ w)) * item_mat[it_id]\n",
    "\n",
    "            # applying wrr to user_mat[u_id]\n",
    "            user_mat[u_id] = self.wrr(\n",
    "                    w, a_mat, r_vec, c_mat, item_mat, u_id, iter_count\n",
    "            )\n",
    "\n",
    "    def implicit_als(self,\n",
    "                     rank,\n",
    "                     iter_count,\n",
    "                     lambda_val,\n",
    "                     alpha):\n",
    "        \"\"\"\n",
    "        here are used same params as in method `build`\n",
    "        \"\"\"\n",
    "        # TODO try with + I\n",
    "\n",
    "        # formatting confidences matrix\n",
    "        c_user_item = (self.sparse_matrix * alpha).astype('double').tocsr()\n",
    "        c_item_user = c_user_item.T\n",
    "\n",
    "        # initializing user and item representing matrices\n",
    "        user_size, item_size = self.sparse_matrix.shape\n",
    "        user = np.random.rand(user_size, rank) * 0.01  # TODO: try with zeros (perhaps, zero matrices are better, so\n",
    "        item = np.random.rand(item_size, rank) * 0.01  # we could save some time on first iteration)\n",
    "\n",
    "        # algo itself\n",
    "        for _ in range(iter_count):\n",
    "            self.least_squares(c_user_item, user, item, lambda_val)\n",
    "            self.least_squares(c_item_user, item, user, lambda_val)\n",
    "\n",
    "        # defining object's attributes\n",
    "        self.users_matrix, self.items_matrix = sparse.csr_matrix(user), sparse.csr_matrix(item)\n",
    "\n",
    "    def find_similar_item(self,\n",
    "                          item,\n",
    "                          res_n: int = 10):\n",
    "        \"\"\"\n",
    "        :param item: item as it is stored in database\n",
    "            (meant it is in column that was given to load)\n",
    "        :param res_n: count of items to find\n",
    "        :return: `res_n` most similar to `item` items\n",
    "        \"\"\"\n",
    "        item_id = self.item2index(item)\n",
    "        # get vector corresponding to item\n",
    "        item_vec = self.items_matrix[item_id].T\n",
    "        # multiply item_vec to items_matrix,\n",
    "        # so we will just sort scalar products of vectors\n",
    "        scores = self.items_matrix.dot(item_vec).toarray().reshape(1, -1)[0]\n",
    "        # choose top `res_n` and return them\n",
    "        return self.index2item(np.argsort(scores)[::-1][:res_n])\n",
    "\n",
    "    def recommend_to_user(self,\n",
    "                          user,\n",
    "                          res_n: int = 10):\n",
    "        \"\"\"\n",
    "        :param user: user as it is stored in database\n",
    "            (meant it is in column that was given to load)\n",
    "        :param res_n: count of items to recommend\n",
    "        :return: `res_n` most suitable (by RS) items for `user`\n",
    "        \"\"\"\n",
    "        user_id = self.user2index(user)\n",
    "\n",
    "        # to not recommend items user has consumed/interacted\n",
    "        user_interactions = self.sparse_matrix[user_id, :].toarray()\n",
    "        user_interactions = user_interactions.reshape(-1) + 1\n",
    "        user_interactions[user_interactions > 1] = 0\n",
    "\n",
    "        # calculate the recommendation by taking the product\n",
    "        # of user vector with the item vectors\n",
    "        rec_vector = (self.users_matrix[user_id, :] @\n",
    "                      self.items_matrix.T).toarray()\n",
    "\n",
    "        # scaling scores to make them easier to interpret\n",
    "        rec_vector_scaled = self.min_max_scaler.fit_transform(\n",
    "                rec_vector.reshape(-1, 1)\n",
    "        )[:, 0]\n",
    "\n",
    "        # do not multiply, if want consumed items to be recommended too\n",
    "        recommend_vector = user_interactions * rec_vector_scaled\n",
    "\n",
    "        # choose top `res_n` and return them\n",
    "        return self.index2item(np.argsort(recommend_vector)[::-1][:res_n])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4c272b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "implicit_rec = ImplicitRS()\n",
    "implicit_rec.load(\"formatted_data/lastfm2collab.csv\", [\"user_id\", \"item_id\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "458f3fdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.2 s ± 60.6 ms per loop (mean ± std. dev. of 7 runs, 5 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 5 implicit_rec.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "143fc8eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1226, 285)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "implicit_rec.sparse_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d7e079ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hot chip',\n",
       " 'damien rice',\n",
       " 'misfits',\n",
       " 'equilibrium',\n",
       " 'black eyed peas',\n",
       " 'pink floyd',\n",
       " 'jack johnson',\n",
       " 'silverstein',\n",
       " 'linkin park',\n",
       " 'dream theater']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "implicit_rec.find_similar_item(\"linkin park\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "af9ce5aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['frank sinatra',\n",
       " 'tori amos',\n",
       " 'atreyu',\n",
       " 'interpol',\n",
       " 'massive attack',\n",
       " 'manowar',\n",
       " 'dream theater',\n",
       " 'bob marley',\n",
       " 'kate nash',\n",
       " 'u2']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "implicit_rec.recommend_to_user(user=5985)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
